{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tushare as ts\n",
    "import pandas as pd\n",
    "ts.set_token(\"4dfe93632a16f49cae109f45465cc2aa13e6151e3a879cfa23d71d72\")\n",
    "pro = ts.pro_api()\n",
    "\n",
    "\n",
    "df = pro.daily(ts_code='000001.SZ', start_date='2015701', end_date='20230718')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from core.data_processor import DataLoader\n",
    "from core.model import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def model(data):\n",
    "    df=data\n",
    "    #转换为Date,Open,High,Low,Close,Volume\n",
    "    df = df.sort_values(by='trade_date', ascending=True)\n",
    "    df = df[['trade_date','open','high','low','close','vol']]\n",
    "    df.columns = ['Date','Open','High','Low','Close','Volume']\n",
    "    #去掉索引\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    #预览\n",
    "    df.head()\n",
    "    #保存为csv\n",
    "    path = 'data/stoke.csv'\n",
    "    df.to_csv(path,index=False)\n",
    "\n",
    "    #修改config.json中的参数\n",
    "    with open('config.json') as f:\n",
    "        config = json.load(f)\n",
    "        #data.filename\n",
    "        config['data']['filename'] = 'stoke.csv'\n",
    "        #data.train_test_split\n",
    "        config['data']['train_test_split'] = 0.8 #全部用于训练,一次性预测\n",
    "        #data.sequence_length\n",
    "        config['data']['sequence_length'] = 50 #一次性预测\n",
    "\n",
    "    #保存修改后的config.json\n",
    "    with open('config.json','w') as f:\n",
    "        json.dump(config,f,indent=4)\n",
    "\n",
    "    #\n",
    "    configs = json.load(open('config.json', 'r'))\n",
    "    if not os.path.exists(configs['model']['save_dir']): os.makedirs(configs['model']['save_dir'])\n",
    "\n",
    "    #加载数据\n",
    "    data = DataLoader(\n",
    "        os.path.join('data', configs['data']['filename']),\n",
    "        configs['data']['train_test_split'],\n",
    "        configs['data']['columns']\n",
    "    )\n",
    "    #构建模型\n",
    "    model = Model()\n",
    "    model.build_model(configs)\n",
    "    x, y = data.get_train_data(\n",
    "        seq_len=configs['data']['sequence_length'],\n",
    "        normalise=configs['data']['normalise']\n",
    "    )\n",
    "\n",
    "\n",
    "    #训练模型\n",
    "\n",
    "    '''\n",
    "    # in-memory training\n",
    "    model.train(\n",
    "        x,\n",
    "        y,\n",
    "        epochs = configs['training']['epochs'],\n",
    "        batch_size = configs['training']['batch_size'],\n",
    "        save_dir = configs['model']['save_dir']\n",
    "    )\n",
    "    '''\n",
    "    # out-of memory generative training\n",
    "    steps_per_epoch = math.ceil((data.len_train - configs['data']['sequence_length']) / configs['training']['batch_size'])\n",
    "    model.train_generator(\n",
    "        data_gen=data.generate_train_batch(\n",
    "            seq_len=configs['data']['sequence_length'],\n",
    "            batch_size=configs['training']['batch_size'],\n",
    "            normalise=configs['data']['normalise']\n",
    "        ),\n",
    "        epochs=configs['training']['epochs'],\n",
    "        batch_size=configs['training']['batch_size'],\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        save_dir=configs['model']['save_dir']\n",
    "    )\n",
    "\n",
    "\n",
    "    #预测\n",
    "    #有修改\n",
    "    #取最后一段长为sequence_length的数据\n",
    "    x_test=x[-configs['data']['sequence_length']:]\n",
    "    y_test=y[-configs['data']['sequence_length']:]\n",
    "    print(x_test.shape)\n",
    "    print(y_test.shape)\n",
    "    print(y_test)\n",
    "    # x_test, y_test = data.get_test_data(\n",
    "    #     seq_len=configs['data']['sequence_length'],\n",
    "    #     normalise=configs['data']['normalise']\n",
    "    # )\n",
    "    predictions = model.predict_sequences_multiple(x_test, configs['data']['sequence_length'], configs['data']['sequence_length'])\n",
    "    # predictions = model.predict_sequence_full(x_test, configs['data']['sequence_length'])\n",
    "    # predictions = model.predict_point_by_point(x_test)\n",
    "    predictions = predictions[0]\n",
    "    #只根据预测结果的第一天和预测结果的平均值,返回1(涨)或者0(跌)\n",
    "    average = np.average(predictions)\n",
    "    print(\"LSTM:预测结果的平均值(normalised)为:{}\".format(average))\n",
    "    if(predictions[0]>average):\n",
    "        print(\"LSTM:预测结果为:涨\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"LSTM:预测结果为:跌\")\n",
    "        return 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensflowForLSTM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
